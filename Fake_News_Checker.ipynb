{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72d4ddcc",
   "metadata": {},
   "source": [
    "# Training machine to spot fake news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b36fbe",
   "metadata": {},
   "source": [
    "In this tutorial, we will be training a program to spot fake news. This tutorial will be run on the Jupyter Notebook environment, which is a bit different from that of a conventional coding environment. If you are not familiar with Jupyter Notebook, this tutorial is a good way to get you started on it too!\n",
    "\n",
    "You can see that this Python solution is segmentized into many code blocks (the different grey boxes). You can run each code blocks sequentially by clicking on the run button at the top of this page after you click into the code blocks. Alternatively, you can enter the Shift-Enter keyboard shortcut after you click into each code block to run them.\n",
    "\n",
    "In this tutorial you would not be doing any coding, your primary task is to run through the code and examine the output results. If you have the extra time, you can spend some effort into understanding what the code is trying to do!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9190f19f",
   "metadata": {},
   "source": [
    "Dataset retrieved from: https://github.com/ajayjindal/Fake-News-Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4348068b",
   "metadata": {},
   "source": [
    "## Importing and preparing data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13670ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules and functions\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "import numpy as np\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3912269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data into a dataframe\n",
    "df = pd.read_csv('fake_or_real_news.csv', index_col = 'number', usecols = ['number', 'title', 'text', 'label'], nrows = 2000)\n",
    "\n",
    "# fills any empty cells with a common word\n",
    "df.fillna(\"the\", inplace = True)\n",
    "\n",
    "# examine dataframe df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275f126c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dedicate array y as table containing all the labels (i.e FAKE or REAL labelling of news)\n",
    "y = df[\"label\"]\n",
    "\n",
    "# examine array y\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afa254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into 2 different subsets, one used for training our model (X_train) and the other used for testing (X_test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"text\"], y, test_size = 0.33, random_state = 52)\n",
    "\n",
    "#Use this function to check the size of new database after split into training and testing pools\n",
    "print(y_train.shape) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5922a1bf",
   "metadata": {},
   "source": [
    "## Training and testing of data using different classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8811fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "#Generate word count for each unique word for X_train\n",
    "count_train = count_vectorizer.fit_transform(X_train.values.astype('U'))\n",
    "\n",
    "#Generate word count for each unique word for X_test\n",
    "count_test = count_vectorizer.transform(X_test.values.astype('U')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f25e68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#by declaring max_df = 0.95 the program removes words which appear in more than 95% of the articles\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95)\n",
    "\n",
    "#Generate TFIDF-values for X_train\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train.values.astype('U')) \n",
    "\n",
    "#Generate TFIDF-values for X_test\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test.values.astype('U')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d60b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function for creating a confusion matrix\n",
    "def plot_confusion_matrix(number,cm, classes,title, normalize=False,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    plt.figure(number)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6656270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize text classifer using Multinomial N-B classification system on tfidf model\n",
    "clf = MultinomialNB()\n",
    "#instruct program to find patterns between text articles and real/fake label in training pool\n",
    "clf.fit(tfidf_train, y_train)\n",
    "\n",
    "#use newfound pattern to predict article text from testing pool\n",
    "prediction = clf.predict(tfidf_test)\n",
    "\n",
    "#compare the result of real/fake classification to the actual labelling\n",
    "score = metrics.accuracy_score(y_test, prediction)\n",
    "print(\"accuracy N-B on TFIDF: %0.3f\" % score)\n",
    "\n",
    "#calculate Confusion Matrix (CM) and generate date for plotting CM\n",
    "cm = metrics.confusion_matrix(y_test, prediction, labels=['FAKE', 'REAL'])\n",
    "plot_confusion_matrix(\"1\", cm, classes=['FAKE', 'REAL'], title=\"N-B on TFIDF\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67ce187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize text classifer using Passive Aggressive classification system on tfidf model\n",
    "\n",
    "clf = PassiveAggressiveClassifier()\n",
    "clf.fit(tfidf_train, y_train)\n",
    "prediction = clf.predict(tfidf_test)\n",
    "score = metrics.accuracy_score(y_test, prediction)\n",
    "print(\"accuracy P-A on TFIDF: %0.3f\" % score)\n",
    "cm = metrics.confusion_matrix(y_test, prediction, labels=['FAKE', 'REAL'])\n",
    "plot_confusion_matrix(\"2\", cm, classes=['FAKE', 'REAL'], title=\"P-A on TFIDF\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df39014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize text classifer using Multinomial N-B classification system on count vectorizer model\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(count_train, y_train)\n",
    "prediction = clf.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, prediction)\n",
    "print(\"accuracy N-B on CountVec: %0.3f\" % score)\n",
    "cm = metrics.confusion_matrix(y_test, prediction, labels=['FAKE', 'REAL'])\n",
    "plot_confusion_matrix(\"3\", cm, classes=['FAKE', 'REAL'], title=\"N-B on CountVec\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a09958",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize text classifer using Passive Aggressive classification system on count vectorizer  model\n",
    "\n",
    "clf = PassiveAggressiveClassifier()\n",
    "clf.fit(count_train, y_train)\n",
    "prediction = clf.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, prediction)\n",
    "print(\"accuracy P-A on TFIDF: %0.3f\" % score)\n",
    "cm = metrics.confusion_matrix(y_test, prediction, labels=['FAKE', 'REAL'])\n",
    "plot_confusion_matrix(\"4\", cm, classes=['FAKE', 'REAL'], title=\"P-A on CountVec\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66dddb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
